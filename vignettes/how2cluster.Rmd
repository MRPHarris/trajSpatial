---
title: "HYSPLIT trajectory clustering through R"
author: "Matt Harris (m.harris@gns.cri.nz)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{HYSPLIT trajectory clustering through R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, message = FALSE, warning = FALSE, include = FALSE}
# This file is used to generate a tutorial text for trajSpatial. 

# knitr::opts_chunk$set(
#   collapse = TRUE,
#   comment = "#>"
# )



```

## Introduction
This is a tutorial document for the `trajSpatial` package for R (v.`r R.Version()$major`). The focus is on how to perform cluster analysis of trajectory endpoint data generated with the NOAA HYSPLIT model through the `splitr` package [@Stein2015;@Iannone2023]. Here are some key features:

* Organise and collate trajectory endpoint data to streamline cluster analysis
* Easily parse outputs from the clustering program
* Assign raw trajectory data to cluster assignments generated by the hysplit cluster program
* Recode cluster numbering from the initial, algorithmic assignments to your own system. 
* Read and plot cluster spatial variance (DELPCT) data. 
* Add new trajectory data to *existing* clusters

A quick note on terms:

* A *trajectory* is a set of points that together comprise the three-dimensional travel of an air parcel or modelled particle through a modelled atmosphere. A trajectory may move forwards through time (e.g., away from a release point) or backwards (e.g., towards a point of deposition). 
* An *endpoint* is a single data point along a trajectory's travel path. A single, 120-hour (5-day) trajectory path may be comprised of 121 endpoints from the HYPSLIT model (which outputs data in hourly time-steps).
* A *termination point* is the terminal endpoint of a trajectory, furthest from the receptor or release point.
* A *receptor* or *release point* is the location that is used to initiate the trajectories' travel, either forwards or backwards through time. 

## A quick how-to on generating trajectories
The bulk of this tutorial deals with clustering trajectory data. However, to do so you will need some trajectory data! A sample dataset is provided with this package by default. 

To generate trajectories, have a look at the guides provided by the [splitr package](https://github.com/rich-iannone/splitr).

Generally, after running the HYSPLIT trajectory model through `splitr`, you are left with two key products:

* a series of endpoint files produced by the model.
* by extension, a data-frame of structured trajectory endpoint data constructed from the endpoint files by `splitr::trajectory_read()`.

Cluster analysis using the HYSPLIT-native clustering system will use the first data product, the endpoint files produced by the model itself. However, later stages of trajectory cluster analysis allow the investigator to associate individual trajectories with their assigned cluster. This can facilitate more detailed analysis of trajectory data, including the temporal frequency of within- and between-cluster trajectories. 

## Installing trajSpatial
You can install the trajSpatial package from github with the following lines. The package is not currently on CRAN.
```{r eval=FALSE, include=TRUE}
install.packages('devtools') # Install the devtools package if necessary.
devtools::install_github("MRPHarris/trajSpatial")
```

## Options for clustering trajectory datasets
There are many ways to spatially cluster trajectory endpoint data [@Dorling1992;@Cui2021;@Kassomenos2010]. Experimentation and a review of the existing literature in your own analysis context is encouraged. In R, you can perform a number of clustering techniques using the following packages and functions, provided the trajectory data is appropriately formatted.

Hierarchical clustering:

* `stats` package. The function `stats::hclust()` will compute one of several hierarchical clustering methods on a distance matrix produced by `stats::dist()`. This could presumably be applied to trajectory data.
* The HYSPLIT cluster algorithm. The [HYSPLIT-native clustering method](https://www.ready.noaa.gov/documents/Tutorial/html/traj_clus.html) uses hierarchical clustering based upon Ward variance minimization. The rest of this tutorial deals with using this method. I have found it best for trajectories at higher latitudes.

K-means clustering:

* K-means clustering (`stats` package). The function `stats::hclust()` will compute kmeans on a supplied matrix using one of several different algorithms.
* K-means 'around medoid' clustering using either Euclidean or angle-informed distances (`openair package`). This is allegedly a more robust version of k-means [@Carslaw2012;@Reynolds2006;@Schubert2021]. A trajectory dataframe from `splitr::trajectory_read()` can be converted to an openair-compliant trajectory dataset with `trajSpatial::convert_openair()`.

## Conducting hierarchical (Ward variance minimisation) clustering with trajSpatial and HYSPLIT

This tutorial assumes you've run some trajectories with the splitr package, ideally of sufficient quantity to warrant clustering. The algorithm will not run with fewer than 16 trajectories. This means you have successfully installed the hysplit program and its dependencies, and then run the model through splitr. You have a series of endpoint files sitting somewhere on your computer, and splitr has returned you a data frame of the endpoint data variables (lat, lon, timestamps, etc.) in your R environment. You will need to be able to run not just HYSPLIT (through e.g., splitr or the command-line), but also the GUI, in order to run the clustering algorithm.

```{r eval=FALSE, include=TRUE}
install.packages('devtools') # Install the devtools package if necessary.
devtools::install_github("MRPHarris/trajSpatial")
```

Currently, this package provides functions to (1) assist in managing endpoint files before and after clustering, and (2) parsing/analysing the outputs from the clustering algorithm provided by the HYSPLIT program. At present, clustering itself *is still performed using the HYSPLIT GUI* ([Relevant user guide page](https://www.ready.noaa.gov/hysplitusersguide/S255.htm)). Most of the internal package functions were written on a windows PC, and so there will be assumptions made about file paths and the like. 

A typical workflow for clustering with the trajSpatial package goes something like:

1. Remove and archive any existing endpoint files from the endpoints directory (on windows, C:/hysplit/cluster/endpts/), using `archive_cluster_endpoints()`. This will move them to a subdirectory within the cluster/endpts folder called 'archive'. If you don't care about keeping the files currently in that directory (i.e., you have them stored elsewhere), you can use `clear_dir()`. This will delete all endpoint files in the cluster/endpts folder.

2. Move the endpoint files to be clustered to the endpoints directory, using `collate_endpts()`. 

3. Create the cluster INFILE. You can do this in the HYSPLIT GUI, or with the function `make_INFILE()`.

4. In the HYSPLIT GUI, run the cluster analysis. Special runs -> Run cluster analysis. 

5. Optionally, read and plot the cluster algorithm's total spatial variance (TSV) data with `read_DELPCT()` and `plot_DELPCT()`.

6. Narrow down on a desired number of clusters by plotting the clusters (in the GUI) and looking for significant changes in TSV using the DELPCT files in the GUI or from the previous step. It is considered best practice to choose a number of clusters that proceeds a large increase in TSV (which will increase as the # of clusters decreases).

7. In the GUI, choose the desired number of clusters and hit 'display means'. This will produce necessary tdump files for this set of clusters that are required for subsequent steps. 

8. Display the cluster means

### Setting up a cluster analysis

The HYSPLIT cluster algorithm takes in the endpoint files produced by the trajectory model. By default, the cluster program will look for them within the 'cluster/endpts/' subdirectory (on Windows, this is by default found at C:/hysplit/cluster/endpts/'). 


```{r, message = FALSE, warning = FALSE, include = FALSE}
## Dummy code from relevant script TBA

## Section notes
# Code for running clusters with HYSPLIT.
## Setup: create directories for the import/export requirements.
date_dir <- era5_dir # where are the date vectors stored?
cluster_export_dir <- paste0(traj_data_dir_new,"HYSPLIT GUI Clustering/") # where are we exporting cluster data?
target_dir <- "D:/DATA/HYSPLIT Files/HYSPLIT Runs Aug2022/PH_1500m_240hr_reanalysis_endpoints/" # where are the trajectory endpoint files stored?
run_name <- "PH_1500m_reanalysis_120hr_precip_2d12h" # what's the name of this trajectory endpoint set?
## Step 1: collate endpoints using the supplied date vectors.
type = 'reanalysis'
# date_dir <- era5_dir
dates_precip_1pct <- readRDS(file = paste0(date_dir,"precip_1pct_days.rds"))
if(type == 'reanalysis'){
  date_vec <- dates_precip_1pct %>%
    dplyr::filter(date >= as_date("1980-01-01"))
  date_vec <- date_vec$date
} else {
  date_vec <- dates_precip_1pct %>%
    dplyr::filter(date >= as_date("2005-01-01"))
  date_vec <- date_vec$date
}
archive_cluster_endpoints()
collate_endpts(from_dir = target_dir,
               recurse = TRUE,
               date_vec = date_vec,
               hour_vec = "12")

## S2: Run trajectories
# Go into HYSPLIT, and run trajectories.

## Step 3: get the DELPCT file
# This is now a part of trajSpatial::read_DELPCT()
library(trajSpatial)
DELPCT_it <- trajSpatial::read_DELPCT(max_clusters = 100)
# saveRDS(DELPCT_it, file = paste0(cluster_export_dir,"DELPCT outputs/",run_name,".rds"))
# write.csv(DELPCT_it,file = paste0(cluster_export_dir,"DELPCT outputs/",run_name,".csv"))

## Optional plotting
plot_DELPCT(DELPCT_it, threshold = 20)

## Step 4: export the mean files when they are created.
# After identifying appropriate numbers of trajectories, put them into their means.
# To do this, 'assign trajectories to means', then hit 'display means'. You don't have to actually plot them,
# but this second step creates the tdump files.

mean_tabs <- get_clusmeans_tdump()

# Save means
saveRDS(object = mean_tabs, file = paste0(cluster_export_dir,"Mean cluster files/",run_name,"_means.rds"))



```

## Draft/out-of-date text below this header

Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
